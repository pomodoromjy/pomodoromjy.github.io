<!DOCTYPE html>
<html>
<head>
<title>检索分类：二值化数据和分类器</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<style type="text/css">
/* GitHub stylesheet for MarkdownPad (http://markdownpad.com) */
/* Author: Nicolas Hery - http://nicolashery.com */
/* Version: b13fe65ca28d2e568c6ed5d7f06581183df8f2ff */
/* Source: https://github.com/nicolahery/markdownpad-github */

/* RESET
=============================================================================*/

html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, img, ins, kbd, q, s, samp, small, strike, strong, sub, sup, tt, var, b, u, i, center, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td, article, aside, canvas, details, embed, figure, figcaption, footer, header, hgroup, menu, nav, output, ruby, section, summary, time, mark, audio, video {
  margin: 0;
  padding: 0;
  border: 0;
}

/* BODY
=============================================================================*/

body {
  font-family: Helvetica, arial, freesans, clean, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  color: #333;
  background-color: #fff;
  padding: 20px;
  max-width: 960px;
  margin: 0 auto;
}

body>*:first-child {
  margin-top: 0 !important;
}

body>*:last-child {
  margin-bottom: 0 !important;
}

/* BLOCKS
=============================================================================*/

p, blockquote, ul, ol, dl, table, pre {
  margin: 15px 0;
}

/* HEADERS
=============================================================================*/

h1, h2, h3, h4, h5, h6 {
  margin: 20px 0 10px;
  padding: 0;
  font-weight: bold;
  -webkit-font-smoothing: antialiased;
}

h1 tt, h1 code, h2 tt, h2 code, h3 tt, h3 code, h4 tt, h4 code, h5 tt, h5 code, h6 tt, h6 code {
  font-size: inherit;
}

h1 {
  font-size: 28px;
  color: #000;
}

h2 {
  font-size: 24px;
  border-bottom: 1px solid #ccc;
  color: #000;
}

h3 {
  font-size: 18px;
}

h4 {
  font-size: 16px;
}

h5 {
  font-size: 14px;
}

h6 {
  color: #777;
  font-size: 14px;
}

body>h2:first-child, body>h1:first-child, body>h1:first-child+h2, body>h3:first-child, body>h4:first-child, body>h5:first-child, body>h6:first-child {
  margin-top: 0;
  padding-top: 0;
}

a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 {
  margin-top: 0;
  padding-top: 0;
}

h1+p, h2+p, h3+p, h4+p, h5+p, h6+p {
  margin-top: 10px;
}

/* LINKS
=============================================================================*/

a {
  color: #4183C4;
  text-decoration: none;
}

a:hover {
  text-decoration: underline;
}

/* LISTS
=============================================================================*/

ul, ol {
  padding-left: 30px;
}

ul li > :first-child, 
ol li > :first-child, 
ul li ul:first-of-type, 
ol li ol:first-of-type, 
ul li ol:first-of-type, 
ol li ul:first-of-type {
  margin-top: 0px;
}

ul ul, ul ol, ol ol, ol ul {
  margin-bottom: 0;
}

dl {
  padding: 0;
}

dl dt {
  font-size: 14px;
  font-weight: bold;
  font-style: italic;
  padding: 0;
  margin: 15px 0 5px;
}

dl dt:first-child {
  padding: 0;
}

dl dt>:first-child {
  margin-top: 0px;
}

dl dt>:last-child {
  margin-bottom: 0px;
}

dl dd {
  margin: 0 0 15px;
  padding: 0 15px;
}

dl dd>:first-child {
  margin-top: 0px;
}

dl dd>:last-child {
  margin-bottom: 0px;
}

/* CODE
=============================================================================*/

pre, code, tt {
  font-size: 12px;
  font-family: Consolas, "Liberation Mono", Courier, monospace;
}

code, tt {
  margin: 0 0px;
  padding: 0px 0px;
  white-space: nowrap;
  border: 1px solid #eaeaea;
  background-color: #f8f8f8;
  border-radius: 3px;
}

pre>code {
  margin: 0;
  padding: 0;
  white-space: pre;
  border: none;
  background: transparent;
}

pre {
  background-color: #f8f8f8;
  border: 1px solid #ccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px;
}

pre code, pre tt {
  background-color: transparent;
  border: none;
}

kbd {
    -moz-border-bottom-colors: none;
    -moz-border-left-colors: none;
    -moz-border-right-colors: none;
    -moz-border-top-colors: none;
    background-color: #DDDDDD;
    background-image: linear-gradient(#F1F1F1, #DDDDDD);
    background-repeat: repeat-x;
    border-color: #DDDDDD #CCCCCC #CCCCCC #DDDDDD;
    border-image: none;
    border-radius: 2px 2px 2px 2px;
    border-style: solid;
    border-width: 1px;
    font-family: "Helvetica Neue",Helvetica,Arial,sans-serif;
    line-height: 10px;
    padding: 1px 4px;
}

/* QUOTES
=============================================================================*/

blockquote {
  border-left: 4px solid #DDD;
  padding: 0 15px;
  color: #777;
}

blockquote>:first-child {
  margin-top: 0px;
}

blockquote>:last-child {
  margin-bottom: 0px;
}

/* HORIZONTAL RULES
=============================================================================*/

hr {
  clear: both;
  margin: 15px 0;
  height: 0px;
  overflow: hidden;
  border: none;
  background: transparent;
  border-bottom: 4px solid #ddd;
  padding: 0;
}

/* TABLES
=============================================================================*/

table th {
  font-weight: bold;
}

table th, table td {
  border: 1px solid #ccc;
  padding: 6px 13px;
}

table tr {
  border-top: 1px solid #ccc;
  background-color: #fff;
}

table tr:nth-child(2n) {
  background-color: #f8f8f8;
}

/* IMAGES
=============================================================================*/

img {
  max-width: 100%
}
</style>
</head>
<body>
<h2><center>检索分类：二值化数据和分类器</h2>
<p>未来媒体研究中心、计算机科学与工程学院、电子科技大学计算机科学与技术学院、北京大学腾讯人工智能实验室马龙技术有限公司</p>
<p><strong>摘要：</strong></p>
<p>本文提出了一种泛型公式，其在加快图像分类模型的训练和调度方面具有重大的意义，特别是在图片种类繁多及图片具有高维特征的情况下。作为核心思想，该方法通过二进制哈希编码表示了图像和分类器，与此同时，它还可以从测试数据中学习。因此，图像分类可归纳为在汉明空间内检索其类编码。</p>
<p>特殊的是，我们将多类图片分类看成基于二进制变量的最优化问题。该最优化问题基于二进制分类器和图片汉明编码交替出现。得益于二进制编码的特性，我们发现这些子问题可以用二进制二次方程( BQP )或线性方程解决。因此，为了解决二进制二次方程问题( BQP ),我么提出了一种全新的高效率的比特翻转程序以得到局部最优解。该公式能支撑大量的经验损失函数，并且文中通过指数损失和线性损失进行了实例化。而且已经对几个代表性的基准图像数据进行了综合性的评估。该实验始终保持在无精度损失的情况下降低模型训练和调度过程中的计算和内存复杂度。</p>
<p><strong>计算分类系统概念</strong></p>
<ul>
<li>
<p>信息系统---&gt;相似性度量</p>
</li>
<li>
<p>计算方法论---&gt;分类监督性学习</p>
</li>
</ul>
<p><strong>关键字</strong></p>
<p>哈希；二进制编码</p>
<p><strong>1 简介</strong></p>
<p>近几年，由于数据数量和数据维度特征的爆炸性增长，大规模的视觉识别问题激起了学术界和工业界广泛的研究热情。使用传统分类器将图片划分成上千个类别通常需要进行大量的计算，例如在通用计算机上使用邻近算法（ k-NN ）和支持向量机算法 （ SVM ）。对于图像分类问题来说，（计算机的）计算和记忆最开始来源于对大量分类器的学习。然而在训练和调度这些分类器阶段复杂度会有所提高。用C 异步分类和D 维度特征分类来执行分类任务，即使最简单的线性模型都由 D X C 个参数构成。</p>
<p align="right" style="color:#808080">last modified:2017-5-14 11:00am </p>
<p>作为本文研究工作中令人激动的例子，网络图像数据组一共包含 21841 种注解图片。当对一些最新的视觉特征（如 4096 维度的深度神经网络）进行测试时，需要学习和存储高达 8000 万的庞大数据，这必将会导致缓慢的训练过程以及低效率的调度解析。现实生活中的应用（例如工业上的图片搜索引擎）通常需要实时的反应。因此传统的多类图片分类器训练方法仍有很大的提升空间。</p>
<p>简化的二进制哈希编码在促进大规模的相似图片检索时取得了不可忽视的成功，该方法在学术上被称为图像哈希算法。在一系列典型的监督学习中，汉明码在保证相同语义图片之间的最小汉明距离方面是最佳的。事实上，由于图像哈希算法技术的低存储以及可靠的可扩展性大数据，该方法已经被广泛的应用。</p>
<p>尽管用于图片检索的哈希算法技术已经是一个被广泛探索研究的领域，然而它的大规模优化应用在机器学习和计算机视觉领域仍是一个新兴话题。</p>
<p align="right" style="color:#808080">last modified:2017-5-15 9:20am </p>
<p>直观地说，人们可以利用基于哈希编码的笨拙方法来实现图像分类任务，例如 KNN 算法。训练和测试图像都用相同的哈希函数来索引。通过在哈希桶里添加的大量的语义标签，一组新的图片将会被分类。然而，由于哈希编码只在图片搜索方面有最优解，所以这种笨拙的组合并不能保证图片识别的精确度。而我们做的相关工作近似于通过基于哈希编码的数据表示法来解决非线性支持向量机核算法问题。这些方法首次提出了一系列将原始特征转换为二进制编码的哈希函数。二进制哈希比特之间的内积运算证明原始的非线性核函数（ 如 RBF 核函数）在理论上近似成立。这种处理方法有两个显著的优点：所需要的哈希比特仅在一定程度上取决于原始的特征维度；并且与此同时最优化非线性问题被转换成线性问题。主要的缺点是，这些工作仍依赖于基于二进制特征的有规律的有实际价值的分类器。尽管它能够直接运用到线性问题中，但潜在的二进制编码的优点并没有得到充分利用。</p>
<p align="right" style="color:#808080">last modified:2017-5-16 9:36am </p>
<p>我们的工作是对上述研究的重要扩展。通过二值化分类器特征及权重我们提高了分类模型的精确度。换句话说，我们的目标是发展一个一般的多类分类器框架。分类器权重和图片编码可以同时被学习。重要的是，二者均可以由二进制哈希编码表示。如此一来分类问题便被转换为一种等价而简单的操作，称之为寻找查询与 C 二进制权重向量间的最小汉明距离。所提出方法的概述如图二所示。</p>
<p>本次研究工作的主要技术贡献总结如下：</p>
<p>（ 1 ）我们通过将分类器和图片特征二进制化定义了一个新兴的问题，同时通过统一的公式对它们进行学习。我们最大的目标就是加快大规模图片的识别。我们的研究工作呈现了一个从未被探索的研究方向——拓广哈希技术，从快速图像搜索到新话题——加快的哈希图片分类技术。</p>
<p>（ 2 ）为解决二进制最优问题我们提出了一个高效的方法。将两组二进制变量（图像编码及二进制分类器权重）进行分离并且采用了一种交替最小风格的程序。特别的是，我们指出了这些子问题或是二进制二次问题（ BQP ）或是线性问题。而且针对二进制二次问题 （ BQP ）我们设计出了一种高效的比特翻转程序。得益于二进制的特殊性质，我们可以确定该二进制二次问题（ BQP ）的局部最优解。</p>
<p>（ 3 ）我们的公式能支撑大量的经验损失函数，并且本文中通过指数和线性损失进行了实例化。在定量分析中，我们将两种变量与关键的矛盾的算法进行了比较，特别是与以线性实验著称的 SVM 算法的最优实现进行比较。</p>
<p align="right" style="color:#808080">last modified:2017-5-17 20：02pm </p>
<p>如图一所示，我们提出的方法在训练和测试 CPU 的时间以及分类精确度方面有着突出的优势。
<center> 精确度<img src="./images/001.PNG" alt="捕获" /></center>
​                             <center>编码长度</center></p>
<p><center> ( a )分类精确度</center></p>
<p><center>训练时间 <img src="./images/001.PNG" alt="捕获1" /></center>
                            <center>编码长度</center>       <br />
<center>( b )训练复杂度</center></p>
<p>图一：</p>
<p>此处省略 n 多字……,实在翻不下去了（手动笑哭）<br/></p>
<p><strong>5. 结语</strong><br/>
本文提出了一种全新的分类框架，通过该框架分类问题被转换成为在汉明空间中寻找最小二进制权重编码的问题，（图片）特征和分类器权重向量都同时使用二进制哈希编码来训练。该框架利用了大量的经验损失函数，并针对代表性的指数损失和线性损失进行研究。对于二进制分类器和图像哈希编码的两个子问题，分别建立了二进制二次程序 （ BQP ）以及线性程序。实际上，针对二进制二次问题 （ BQP ），我们提出了一种高效率的比特翻转程序以得到局部最优解。我们所提出的方法在保证分类精确度的情况下降低了训练和调度模型的计算复杂度。我们也对稀疏二进制编码模型进行了讨论，该方法为进一步降低计算复杂度和内存开销提供了实际的方法。<br/></p>
<p align="right" style="color:#808080">last modified:2017-5-29 20：12pm </p>
</body>
</html>
<!-- This document was created with MarkdownPad, the Markdown editor for Windows (http://markdownpad.com) -->
